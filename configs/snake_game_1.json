{
	"models": [
		"gpt-4-32k"
	],
	"agents": [
		{
			"type": "UserProxyAgent",
			"name": "user_proxy",
			"human_input_mode": "ALWAYS",
			"max_consecutive_auto_reply": 10,
			"llm_config": {},
			"code_execution_config": {
				"work_dir": "coding",
				"use_docker": false
			}
		},
		{
			"type": "AssistantAgent",
			"name": "assistant",
			"llm_config": {
				"seed": 412,
				"temperature": 0
			}
		}
	],
	"start_conversation": {
		"initiator": "user_proxy",
		"recipient": "assistant"
	}
}
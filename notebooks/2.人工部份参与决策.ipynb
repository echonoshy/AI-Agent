{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGEN 第二课： 人工如何部分参与agent的决策过程以及死循环情况的处理\n",
    "\n",
    "通过第一个例子，我们初步了解了在没有人工干预的情况下，Autogen框架是如何控制2个不同种类的agent通过对话完成一个任务的。\n",
    "但是在绝大多数的情况下，我们都希望人工能够参与进去，并且在合适的时候给出纠正或者提出其他的需求。\n",
    "下面这个例子中，我们逐步递进，介绍人工如何部分参与决策的过程。\n",
    "这里的部分参与你可以理解为：在正常情况下agent都拥有足够的智能，可以处理大部份的情况。只有当陷入了难以决策的困难时，才会寻求人类的帮助。\n",
    "\n",
    "在代码中表现为，assistant agent会在合适的时候返回\"TERMINATE\"暗号，跟user agent说了声，“这样搞不是个事啊，先停一停，听听老板啥意见”， 这个时候user agent就会停下来等待人类的指令。 在得到新指令的情况下，并将新指令传达给assistant agent, 继续干活，否则流程就会在这个地方一直停下来。 \n",
    "\n",
    "当然，除了暗号的形式外，还有一个常见的做法就是设定对话的最后轮次数量，当2个或多个agent对话的轮次达到最大限制的时候，也会停下来等人类的指定输入了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置环境\n",
    "\n",
    "1. 你需要安装autogent的库， 要求python版本>=3.8\n",
    "2. 配置openai 或者 azure openai的api key, 并将key写入到一个名为 \"OAI_CONFIG_LIST\"的文件中，并将该文件放在项目目录下。或者将其配置到你的环境变量中。\n",
    "\n",
    "OAI_CONFIG_LIST的内容结构如下：\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyautogen~=0.1.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Who should read this paper: https://arxiv.org/abs/2308.08155\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To determine who should read the paper, we need to first understand the content and context of the paper. We can do this by fetching the abstract of the paper from the provided URL and analyzing it. \n",
      "\n",
      "Here is a Python script that uses the BeautifulSoup library to scrape the abstract from the webpage. \n",
      "\n",
      "```python\n",
      "# filename: fetch_abstract.py\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def fetch_abstract(url):\n",
      "    response = requests.get(url)\n",
      "    soup = BeautifulSoup(response.text, 'html.parser')\n",
      "    abstract = soup.find('blockquote', attrs={'class': 'abstract mathjax'}).text.strip()\n",
      "    return abstract\n",
      "\n",
      "url = \"https://arxiv.org/abs/2308.08155\"\n",
      "print(fetch_abstract(url))\n",
      "```\n",
      "\n",
      "Please save this script as `fetch_abstract.py` and run it. This will print the abstract of the paper. Based on the abstract, I can then suggest who might be interested in reading this paper.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Abstract:AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the abstract, the paper is about AutoGen, an open-source framework that allows developers to build applications using multiple agents that can converse with each other to accomplish tasks. The framework is customizable and can operate in various modes that employ combinations of language models, human inputs, and tools. It can be used to program flexible conversation patterns for different applications using both natural language and computer code.\n",
      "\n",
      "Given this, the paper would be of interest to:\n",
      "\n",
      "1. **Software Developers and Engineers**: Especially those interested in building applications that involve conversational agents, language models, and human-computer interaction.\n",
      "\n",
      "2. **Researchers in Artificial Intelligence and Natural Language Processing**: The paper discusses a framework for building applications with conversational agents, which is a topic of interest in these fields.\n",
      "\n",
      "3. **Data Scientists and Machine Learning Engineers**: The framework involves the use of language models, which are a key area of interest in data science and machine learning.\n",
      "\n",
      "4. **Product Managers in Tech Companies**: Especially those working on products that involve conversational agents or human-computer interaction.\n",
      "\n",
      "5. **Students studying Computer Science, AI, or related fields**: The paper could provide insights into practical applications of AI and language models.\n",
      "\n",
      "Please note that this is a general suggestion based on the abstract. The actual content of the paper might be more specific and thus be of interest to a more specific audience. \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# 构建一个assistant agent实例，并且名为 assistant\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"seed\": 42,  # 用于复现结果的种子\n",
    "        \"config_list\": config_list,  \n",
    "        \"temperature\": 0,  \n",
    "    },  \n",
    ")\n",
    "\n",
    "# 构建一个user proxy agent, 并命名为user_proxy\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    #  不同的人类介入程度：\n",
    "    #   never: 人类始终不介入， \n",
    "    #   always: 每一步都需要人类介入， \n",
    "    #   terminate：只有当assistant agent认为当前交互结果没问题了，会返回一个\"terminate\"字符串, （你可以理解为暗号）。此时user proxy agent 才会停下等人类的下一步指令。\n",
    "    human_input_mode=\"TERMINATE\",  \n",
    "    max_consecutive_auto_reply=10,      # 最大的交互轮数，如果超过了会强制退出，等人类指令。\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"), # 如果别的agent返回的结果中带有这个\"TERMINATE\"标记，也会强制退出，等人类指令。\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",   # 临时代码存放的目录，为coding\n",
    "        \"use_docker\": False,    # 设定是否使用docker\n",
    "    },\n",
    "    # 给当前的agent设定独有的prompt\n",
    "    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\n",
    "Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")\n",
    "\n",
    "# 启动两个agent会话\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Who should read this paper: https://arxiv.org/abs/2308.08155\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
